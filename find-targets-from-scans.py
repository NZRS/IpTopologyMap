#!/usr/bin/python

__author__ = 'secastro'

import gzip
import csv
import json
import progressbar
from radix import Radix
import argparse
import glob
import os
from collections import defaultdict

cc_prefix_list = None

parser = argparse.ArgumentParser("Using data sets from scans.io, "
                                 "find suitable targets for probing")
parser.add_argument('--datadir', required=True, help="directory to save output")
parser.add_argument('--scandir', required=True,
                    help="directory with scans.io datasets")
args = parser.parse_args()


def is_ip_contained(a):
    """Use a radix tree to fast lookup the prefix covering the address"""
    for cc, cc_rt in rt.iteritems():
        matching_pfx = cc_rt.search_best(network=a, masklen=32)
        if matching_pfx is not None:
            return [cc, matching_pfx.prefix]

    return None


def extract_unique_address_from_scans(file_list, sample=False):
    """Using files extracted from https://scans.io/ to located potential destinations for testing"""
    addr_list = set()
    pbar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)
    for scan_file in file_list:
        print "Reading file %s" % scan_file
        with gzip.open(scan_file, 'rb') as scan_data:
            csv_r = csv.reader(scan_data)

            # There is a header, skip it
            next(csv_r)

            idx = 0
            for row in csv_r:
                # row[1] is the address we want to check
                idx += 1
                addr_list.add(row[1])

                if idx % 100000 == 0:
                    pbar.update(idx)
                    # print "Read %d records" % idx

                if sample and idx > 100000:
                    break

    return addr_list

"""Read the list of prefixes I'm interested on. Generated by the BGP topology map"""
with open(os.path.join(args.datadir, 'RIR-resources.json')) as prefix_file:
    cc_prefix_list = json.load(prefix_file)

"""Build the radix tree"""
rt = defaultdict(Radix)
for cc, cc_data in cc_prefix_list.iteritems():
    for p1 in cc_data['prefixes']:
        [prefix, masklen] = p1.split("/")
        rt[cc].add(network=prefix, masklen=int(masklen))

address_list = extract_unique_address_from_scans(glob.glob(os.path.join(
    args.scandir, '*.csv.gz')), sample=False)

print "%d addresses will be checked" % (len(address_list))
selected_addr = defaultdict(list)
pbar = progressbar.ProgressBar(max_value=len(address_list)).start()
cnt = 0
for addr in address_list:
    match = is_ip_contained(addr)
    if match is not None:
        selected_addr[match[0]].append(dict(prefix=match[1], address=addr))
    cnt += 1
    if cnt % 100 == 0:
        pbar.update(cnt)

pbar.finish()


for cc, cc_addr in selected_addr.iteritems():
    print "%d addresses found for %s" % (len(cc_addr), cc)
with open(os.path.join(args.datadir, 'dest-addr.json'), 'wb') as addr_file:
    json.dump(selected_addr, addr_file)
